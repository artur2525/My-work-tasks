{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f208a5bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T09:14:16.978328Z",
     "start_time": "2023-09-18T09:14:16.852324Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    \"\"\"Gradient boosting regressor.\"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model to the data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "            y: array-like of shape (n_samples,)\n",
    "\n",
    "        Returns:\n",
    "            GradientBoostingRegressor: The fitted model.\n",
    "        \"\"\"\n",
    "        self.base_pred_ = np.mean(y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the target of new data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "            y: array-like of shape (n_samples,)\n",
    "            The predict values.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = self.base_pred_\n",
    "        return np.array([predictions] * len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6160f2f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T15:01:22.685871Z",
     "start_time": "2023-09-15T15:01:22.682003Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def mse(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Mean squared error loss function and gradient.\"\"\"\n",
    "\n",
    "    loss = np.mean((y_pred - y_true)**2)\n",
    "    grad = 2 * (y_pred - y_true)\n",
    "    \n",
    "    return loss, (grad - loss)\n",
    "\n",
    "\n",
    "def mae(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Mean absolute error loss function and gradient.\"\"\"\n",
    "    \n",
    "    loss = np.mean(abs(y_pred - y_true))\n",
    "    grad = np.where(y_pred == y_true, y_true, np.where((y_pred - y_true) > 0 , 1, -1))\n",
    "    \n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "409145c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T10:13:13.095864Z",
     "start_time": "2023-09-16T10:13:13.081337Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_samples_split=2,\n",
    "        loss=\"mse\",\n",
    "        verbose=False,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.loss = loss\n",
    "        self.verbose = verbose\n",
    "        self.trees_ = []\n",
    "\n",
    "    def _mse(self, y_true, y_pred):\n",
    "\n",
    "        loss = np.mean((y_pred - y_true)**2)\n",
    "        grad = y_pred - y_true\n",
    "        if self.verbose == True:\n",
    "            print(loss)\n",
    "\n",
    "        return loss, grad\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model to the data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "            y: array-like of shape (n_samples,)\n",
    "\n",
    "        Returns:\n",
    "            GradientBoostingRegressor: The fitted model.\n",
    "        \"\"\"\n",
    "        if self.loss == 'mse':\n",
    "\n",
    "            for estim in range(self.n_estimators):\n",
    "                if estim == 0:\n",
    "                    self.base_pred_ = np.mean(y)\n",
    "                    y_pred = -1 * \\\n",
    "                        (y, self._mse(y, np.array([self.base_pred_] * len(y))))\n",
    "\n",
    "                model = DecisionTreeRegressor(max_depth=self.max_depth,\n",
    "                                              min_samples_split=self.min_samples_split).fit(X, y_pred)\n",
    "                self.trees_.append(model)\n",
    "                _, self.grad = self._mse(model.predict(X), y_pred)\n",
    "                y_pred = y_pred * self.learning_rate\n",
    "        else:\n",
    "            for estim in range(self.n_estimators):\n",
    "                if estim == 0:\n",
    "                    self.base_pred_ = np.mean(y)\n",
    "                    y_pred = -1 * \\\n",
    "                        (y, self.loss(y, np.array([self.base_pred_] * len(y))))\n",
    "\n",
    "                model = DecisionTreeRegressor(max_depth=self.max_depth,\n",
    "                                              min_samples_split=self.min_samples_split).fit(X, y_pred)\n",
    "                self.trees_.append(model)\n",
    "                _, self.grad = self.loss(model.predict(X), y_pred)\n",
    "                y_pred = y_pred * self.learning_rate\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the target of new data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "            y: array-like of shape (n_samples,)\n",
    "            The predict values.\n",
    "\n",
    "        \"\"\"\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "\n",
    "        y = self.base_pred_ + predictions\n",
    "        print(y)\n",
    "        for model in self.trees_:\n",
    "            y = y + model.predict(X)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d57b92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T09:44:28.732656Z",
     "start_time": "2023-09-18T09:44:28.721822Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        min_samples_split=2,\n",
    "        loss=\"mse\",\n",
    "        verbose=False,\n",
    "        subsample_size = 0.5,\n",
    "        replace = False\n",
    "\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.verbose = verbose\n",
    "        self.subsample_size = subsample_size\n",
    "        self.replace = replace \n",
    "        self.loss = loss\n",
    "        if loss == 'mse':\n",
    "            self.loss = self._mse\n",
    "        self.trees_ = []\n",
    "\n",
    "    def _mse(self, y_true, y_pred):\n",
    "\n",
    "        loss = np.mean((y_pred - y_true)**2)\n",
    "        grad = y_pred - y_true\n",
    "        if self.verbose is True:\n",
    "            print(loss)\n",
    "\n",
    "        return loss, grad\n",
    "\n",
    "    def _subsample(self, y):\n",
    "        \n",
    "        mask = np.random.choice(range(len(y)), round(len(y) * self.subsample_size), \n",
    "                    replace = self.replace)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model to the data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "            y: array-like of shape (n_samples,)\n",
    "        \n",
    "        Returns:\n",
    "            GradientBoostingRegressor: The fitted model.\n",
    "        \"\"\"\n",
    "        self.base_pred_ = np.mean(y)\n",
    "        y_pred = np.full(len(y), self.base_pred_)\n",
    "        grad = -1 * self.loss(y, y_pred)[1]\n",
    "        for estim in range(self.n_estimators):\n",
    "            mask = self._subsample(y)\n",
    "            model = DecisionTreeRegressor(max_depth=self.max_depth,\n",
    "                    min_samples_split=self.min_samples_split).fit(X[mask], grad[mask])\n",
    "            self.trees_.append(model)\n",
    "            y_pred[mask] = y_pred[mask] +  model.predict(X[mask]) * self.learning_rate\n",
    "            grad = -1 * self.loss(y, y_pred)[1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the target of new data.\n",
    "\n",
    "        Args:\n",
    "            X: array-like of shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "            y: array-like of shape (n_samples,)\n",
    "            The predict values.\n",
    "\n",
    "        \"\"\"\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "\n",
    "        y = self.base_pred_ + predictions\n",
    "        for model in self.trees_:\n",
    "            y = y + model.predict(X) * self.learning_rate\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca2a482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T09:14:20.714801Z",
     "start_time": "2023-09-18T09:14:20.709010Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/artur/my_projects/karpov-projects/intern/dec tree/COUNT_SKU_2023_09_07.csv')\n",
    "y = data['delay_days'].values\n",
    "X = data.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cff21d21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-18T10:01:26.732775Z",
     "start_time": "2023-09-18T10:01:26.588827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.54093217])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingRegressor().fit(X,y).predict(X[0].reshape(1,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
